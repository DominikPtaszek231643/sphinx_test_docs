{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Test Analysis\n",
    "We're going to conduct an Independent Samples T-test to analyse our A/B test. An Indepdent Samples T-test compares the differences between two means of two different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:44.923516Z",
     "start_time": "2024-04-09T20:08:44.911Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export your results to a .csv file and save it to you github repository. Import your .csv file, inspect it, and clean it where neccesary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:44.938544Z",
     "start_time": "2024-04-09T20:08:44.925023Z"
    }
   },
   "outputs": [],
   "source": [
    "# If on Github, load your data\n",
    "df_A = pd.read_csv('./group_A.csv', sep=';')\n",
    "df_B = pd.read_csv('./group_B.csv', sep=';')\n",
    "\n",
    "df_columns =['q1', 'q2', 'q3', 'q4', 'q5']\n",
    "\n",
    "drop_columns = ['Start time', 'Completion time']\n",
    "df_A = df_A.drop(columns=[*drop_columns , \"ID\"] )\n",
    "df_B = df_B.drop(columns=[*drop_columns, 'Id'])\n",
    "\n",
    "df_A.columns  = df_B.columns =  df_columns\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   q1      26 non-null     int64\n",
      " 1   q2      26 non-null     int64\n",
      " 2   q3      26 non-null     int64\n",
      " 3   q4      26 non-null     int64\n",
      " 4   q5      26 non-null     int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 1.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   q1  q2  q3  q4  q5\n0   5   5   6   6   5\n1   7   6   6   5   6\n2   6   4   7   5   5\n3   5   6   5   5   6\n4   6   5   4   5   6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q1</th>\n      <th>q2</th>\n      <th>q3</th>\n      <th>q4</th>\n      <th>q5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6</td>\n      <td>4</td>\n      <td>7</td>\n      <td>5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>6</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA A\n",
    "df_A.info() # Is your data in the right format?\n",
    "df_A.head() # Quick EDA. No? Clean it, you only want the rows and columns containing likert-score data, saved as integers.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:44.954057Z",
     "start_time": "2024-04-09T20:08:44.940543Z"
    }
   },
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   q1      25 non-null     int64\n",
      " 1   q2      25 non-null     int64\n",
      " 2   q3      25 non-null     int64\n",
      " 3   q4      25 non-null     int64\n",
      " 4   q5      25 non-null     int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 1.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   q1  q2  q3  q4  q5\n0   5   5   6   6   5\n1   7   7   7   6   6\n2   7   4   6   7   5\n3   6   5   6   6   5\n4   6   5   4   5   6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q1</th>\n      <th>q2</th>\n      <th>q3</th>\n      <th>q4</th>\n      <th>q5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>7</td>\n      <td>7</td>\n      <td>6</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>4</td>\n      <td>6</td>\n      <td>7</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>5</td>\n      <td>6</td>\n      <td>6</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>5</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA B\n",
    "df_B.info() # Is your data in the right format?\n",
    "df_B.head() # Quick EDA. No? Clean it, you only want the rows and columns containing likert-score data, saved as integers."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:44.969632Z",
     "start_time": "2024-04-09T20:08:44.955054Z"
    }
   },
   "execution_count": 20
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest we leave for tomorrow when we actually have our data. But if you are eager to play around a bit you can simply refresh the survey and fill in a couple of responses to create an A and a B version.\n",
    "\n",
    "Now, let's start analysing our gathered data! This block we won't dive into inferential statistics since it can get complex quite fast; we'll do that in Year 2, block A. For now, you just need to know that we need to test whether the data is normally distributed and whether the variances of both samples are equal. Otherwise, our statistical tests would not be valid and we can therefore not say that the results we're seeing are due to chance. What we are going to statistically ascertain is whether there is a statistically significant different in the mean of a given variable for version A or B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:44.985168Z",
     "start_time": "2024-04-09T20:08:44.972657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk test for q1 in df_A:\n",
      "  p-value: 0.0089\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q2 in df_A:\n",
      "  p-value: 0.0018\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q3 in df_A:\n",
      "  p-value: 0.0169\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q4 in df_A:\n",
      "  p-value: 0.0006\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q5 in df_A:\n",
      "  p-value: 0.0098\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q1 in df_B:\n",
      "  p-value: 0.0\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q2 in df_B:\n",
      "  p-value: 0.0009\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q3 in df_B:\n",
      "  p-value: 0.0001\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q4 in df_B:\n",
      "  p-value: 0.0003\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Shapiro-Wilk test for q5 in df_B:\n",
      "  p-value: 0.0009\n",
      "  The data is not normally distributed. Consider a bootstrapped version.\n",
      "Levene's test for equality of variances:\n",
      "  p-value: 0.1977\n",
      "  The groups have equal variances.\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Run Shapiro-Wilk test for normality for each question in df_A and df_B\n",
    "shapiro_results_a = {}\n",
    "shapiro_results_b = {}\n",
    "for column in df_A.columns:\n",
    "    shapiro_results_a[column] = stats.shapiro(df_A[column])\n",
    "    shapiro_results_b[column] = stats.shapiro(df_B[column])\n",
    "\n",
    "# Run Levene's test to check equality of variances\n",
    "homogeneity = stats.levene(df_A['q1'], df_B['q1'], df_A['q2'], df_B['q2'], df_A['q3'], df_B['q3'], df_A['q4'], df_B['q4'], df_A['q5'], df_B['q5'])\n",
    "\n",
    "# Print the Shapiro-Wilk and Levene's test results\n",
    "for column in shapiro_results_a.keys():\n",
    "    print(f\"Shapiro-Wilk test for {column} in df_A:\")\n",
    "    print(f\"  p-value: {round(shapiro_results_a[column].pvalue, 4)}\")\n",
    "    if shapiro_results_a[column].pvalue > 0.05:\n",
    "        print(\"  The data is normally distributed.\")\n",
    "    else:\n",
    "        print(\"  The data is not normally distributed. Consider a bootstrapped version.\")\n",
    "\n",
    "for column in shapiro_results_b.keys():\n",
    "    print(f\"Shapiro-Wilk test for {column} in df_B:\")\n",
    "    print(f\"  p-value: {round(shapiro_results_b[column].pvalue, 4)}\")\n",
    "    if shapiro_results_b[column].pvalue > 0.05:\n",
    "        print(\"  The data is normally distributed.\")\n",
    "    else:\n",
    "        print(\"  The data is not normally distributed. Consider a bootstrapped version.\")\n",
    "\n",
    "print(f\"Levene's test for equality of variances:\")\n",
    "print(f\"  p-value: {round(homogeneity.pvalue, 4)}\")\n",
    "if homogeneity.pvalue > 0.05:\n",
    "    print(\"  The groups have equal variances.\")\n",
    "else:\n",
    "    print(\"  The groups do not have equal variances. Consider a bootstrapped version.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that is in the right format and we know the column names. Replace 'A' with the column name which holds your original baseline version; A. Replace 'B' with the column name which holds the result of your improved version; B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:45.001818Z",
     "start_time": "2024-04-09T20:08:44.986681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for q1: T-statistic = -1.828533995513482, P-value = 0.07355962674200757\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q2: T-statistic = 0.23357135135475796, P-value = 0.8162908423033319\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q3: T-statistic = -1.8117504102457893, P-value = 0.07615559139945592\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q4: T-statistic = 0.3523108509902171, P-value = 0.7261159989065984\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q5: T-statistic = 0.15822997436527234, P-value = 0.8749258929088156\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Independent Samples T-test when assumptions are not violated.\n",
    "\n",
    "\n",
    "\n",
    "for question in df_columns:\n",
    "    # Run Independent Samples T-test\n",
    "    t_stat, p_value = stats.ttest_ind(df_A[question], df_B[question])\n",
    "    \n",
    "    # Print the results for each question\n",
    "    print(f\"Results for {question}: T-statistic = {t_stat}, P-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"The results are significant; the versions are different enough to exclude chance as the driver.\")\n",
    "        print(\"This indicates that the version (A or B) with a higher/lower average score works better/worse, statistically speaking.\")\n",
    "    else:\n",
    "        print(\"The results are not significant; the changes don't have a real measurable effect.\")\n",
    "        print(\"This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\")\n",
    "    print(\"\\n\")\n",
    "# # Print the results\n",
    "# print(f\"The results are significant if the p-value is significant, which means smaller than 0.05\", \n",
    "# results,\n",
    "# \"\\n\", \n",
    "# \"If the results are significant, that means that the version are different enough to exclude chance for being the driver. So if you version has a higher/lower average score and is statistically significant, then it works better/worse. If the results are not significant then the changes don't have a real measureable effect so maybe it's no better or maybe the questions don't really measure the effect and you should consider rephrase or removing them.There's more to it but that for inferential statistics in year 2.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T20:08:45.017795Z",
     "start_time": "2024-04-09T20:08:45.003733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for q1: T-statistic = -1.828533995513482, P-value = 0.07355962674200757\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q2: T-statistic = 0.23357135135475796, P-value = 0.8162908423033319\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q3: T-statistic = -1.8117504102457893, P-value = 0.07615559139945592\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q4: T-statistic = 0.3523108509902171, P-value = 0.7261159989065984\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n",
      "\n",
      "Results for q5: T-statistic = 0.15822997436527234, P-value = 0.8749258929088156\n",
      "The results are not significant; the changes don't have a real measurable effect.\n",
      "This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Bootstrapped Independent Samples T-test when assumptions are violated\n",
    "rng = np.random.default_rng() # create random sampling\n",
    "\n",
    "results = stats.ttest_ind(a = df_A, b = df_B,\n",
    "                          random_state = rng)\n",
    "\n",
    "\n",
    "for question in df_columns:\n",
    "    # Run Independent Samples T-test\n",
    "    t_stat, p_value = stats.ttest_ind(df_A[question], df_B[question] , random_state=rng)\n",
    "    \n",
    "    # Print the results for each question\n",
    "    print(f\"Results for {question}: T-statistic = {t_stat}, P-value = {p_value}\")\n",
    "    if p_value < 0.05:\n",
    "        print(\"The results are significant; the versions are different enough to exclude chance as the driver.\")\n",
    "        print(\"This indicates that the version (A or B) with a higher/lower average score works better/worse, statistically speaking.\")\n",
    "    else:\n",
    "        print(\"The results are not significant; the changes don't have a real measurable effect.\")\n",
    "        print(\"This might mean the version is no better, or perhaps the questions don't effectively measure the intended effect.\")\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that was our first t-test. Save the results to your learning log in the week 8 and interpret them there. Were they what you expected? What are you going to change to improve your design if neccesary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "119c259948d333b2ddf4ba2ffb3d68be5171f28660b26be40acacf7136fda808"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
